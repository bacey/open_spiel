{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "J0zhqyfea0If",
        "aq0nR0y_a3ju"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bacey/open_spiel/blob/master/Podracer_Architectures_for_Scalable_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMdcuqidrnh0"
      },
      "source": [
        "> Copyright 2021 DeepMind Technologies Limited.\n",
        ">\n",
        "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "> you may not use this file except in compliance with the License.\n",
        ">\n",
        "> You may obtain a copy of the License at\n",
        "> https://www.apache.org/licenses/LICENSE-2.0\n",
        ">\n",
        "> Unless required by applicable law or agreed to in writing, software\n",
        "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "> See the License for the specific language governing permissions and\n",
        "> limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ZkbaRsrpAr"
      },
      "source": [
        "### **Podracer Architectures for Scalable RL**\n",
        "*By Matteo Hessel, Manuel Kroiss, Fabio Viola, Hado van Hasselt*\n",
        "\n",
        "\n",
        "This is a minimal demonstration of how to implement the `Anakin` architecture in JAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zhqyfea0If"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhnJkrYLOvcs"
      },
      "source": [
        "# Install dependencies\n",
        "! pip install chex -q\n",
        "! pip install dm_haiku -q\n",
        "! pip install rlax -q\n",
        "! pip install optax -q\n",
        "\n",
        "# Setup TPU\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "# Imports\n",
        "import chex\n",
        "import jax\n",
        "import haiku as hk\n",
        "from jax import lax\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "import jax.numpy as jnp\n",
        "jax.devices()\n",
        "import optax\n",
        "import rlax\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5UGl5nHrwQy"
      },
      "source": [
        "class TimeIt():\n",
        "\n",
        "  def __init__(self, tag, frames=None):\n",
        "    self.tag = tag\n",
        "    self.frames = frames\n",
        "\n",
        "  def __enter__(self):\n",
        "    self.start = timeit.default_timer()\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *args):\n",
        "    self.elapsed_secs = timeit.default_timer() - self.start\n",
        "    msg = self.tag + (': Elapsed time=%.2fs' % self.elapsed_secs)\n",
        "    if self.frames:\n",
        "      msg += ', FPS=%.2e' % (self.frames / self.elapsed_secs)\n",
        "    print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq0nR0y_a3ju"
      },
      "source": [
        "### Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaD6Gz7AJ2Zx"
      },
      "source": [
        "class Catch:\n",
        "  \"\"\"A JAX implementation of the Catch gridworld.\"\"\"\n",
        "\n",
        "  def __init__(self, rows: int = 10, columns: int = 5):\n",
        "    self._rows = rows\n",
        "    self._columns = columns\n",
        "    self.num_actions = 3\n",
        "\n",
        "  def initial_state(self, rng):\n",
        "    ball_y = 0\n",
        "    ball_x = random.randint(rng, (), 0, self._columns)\n",
        "    paddle_y = self._rows - 1\n",
        "    paddle_x = self._columns // 2\n",
        "    return lax.stop_gradient(jnp.array((ball_y, ball_x, paddle_y, paddle_x), dtype=jnp.int32))\n",
        "\n",
        "  def step(self, rng, state, action):\n",
        "    is_terminal = self.is_terminal(state)\n",
        "    paddle_x = jnp.clip(state[3] + action - 1, 0, self._columns - 1)\n",
        "    state = jnp.array([state[0] + 1, state[1], state[2], paddle_x])\n",
        "    state = lax.select(is_terminal, self.initial_state(rng), state)\n",
        "    return lax.stop_gradient(state)\n",
        "\n",
        "  def observation(self, state):\n",
        "    return (self.render(state), self.reward(state),\n",
        "            self.discount(state), self.is_terminal(state))\n",
        "\n",
        "  def render(self, state):\n",
        "    def f(y, x):\n",
        "      return lax.select(\n",
        "          jnp.bitwise_or(\n",
        "              jnp.bitwise_and(y == state[0], x == state[1]),\n",
        "              jnp.bitwise_and(y == state[2], x == state[3])), 1., 0.)\n",
        "    y_board = jnp.repeat(jnp.arange(self._rows), self._columns)\n",
        "    x_board = jnp.tile(jnp.arange(self._columns), self._rows)\n",
        "    return jax.vmap(f)(y_board, x_board).reshape((self._rows, self._columns, 1))\n",
        "\n",
        "  def reward(self, state):\n",
        "    return lax.select(\n",
        "        self.is_terminal(state), lax.select(state[1] == state[3], 1., -1.), 0.)\n",
        "\n",
        "  def discount(self, state):\n",
        "    return lax.select(self.is_terminal(state), 0., 1.)\n",
        "\n",
        "  def is_terminal(self, state):\n",
        "    return state[0] == self._rows - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsxn_iLXa5S9"
      },
      "source": [
        "### Anakin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGSmAiCHJsas"
      },
      "source": [
        "@chex.dataclass(frozen=True)\n",
        "class TimeStep:\n",
        "  q_values: chex.Array\n",
        "  action: chex.Array\n",
        "  discount: chex.Array\n",
        "  reward: chex.Array\n",
        "\n",
        "def get_network_fn(num_outputs: int):\n",
        "  \"\"\"Define a fully connected multi-layer haiku network.\"\"\"\n",
        "  def network_fn(obs: chex.Array) -> chex.Array:\n",
        "    return hk.Sequential([  # flatten, hidden layer, relu, output layer.\n",
        "        hk.Flatten(), hk.Linear(256), jax.nn.relu, hk.Linear(num_outputs)])(obs)\n",
        "  return hk.without_apply_rng(hk.transform(network_fn))\n",
        "\n",
        "def get_learner_fn(\n",
        "    env, forward_pass, opt_update, rollout_len, agent_discount,\n",
        "    lambda_, iterations):\n",
        "  \"\"\"Define the minimal unit of computation in Anakin.\"\"\"\n",
        "\n",
        "  def loss_fn(params, outer_rng, env_state):\n",
        "    \"\"\"Compute the loss on a single trajectory.\"\"\"\n",
        "\n",
        "    def step_fn(env_state, rng):\n",
        "      obs, reward, discount, is_terminal = env.observation(env_state)\n",
        "      q_values = forward_pass(params, obs[None,])[0]  # forward pass.\n",
        "      action = jnp.argmax(q_values)  # greedy policy.\n",
        "      env_state = env.step(rng, env_state, action)  # step environment.\n",
        "      return env_state, TimeStep(  # return env state and transition data.\n",
        "          q_values=q_values, action=action, discount=discount, reward=reward)\n",
        "\n",
        "    step_rngs = random.split(outer_rng, rollout_len)\n",
        "    env_state, rollout = lax.scan(step_fn, env_state, step_rngs)  # trajectory.\n",
        "    qa_tm1 = rlax.batched_index(rollout.q_values[:-1], rollout.action[:-1])\n",
        "    td_error = rlax.td_lambda(  # compute multi-step temporal diff error.\n",
        "        v_tm1=qa_tm1,  # predictions.\n",
        "        r_t=rollout.reward[1:],  # rewards.\n",
        "        discount_t=agent_discount * rollout.discount[1:],  # discount.\n",
        "        v_t=jnp.max(rollout.q_values[1:], axis=-1),  # bootstrap values.\n",
        "        lambda_=lambda_)  # mixing hyper-parameter lambda.\n",
        "    return jnp.mean(td_error**2), env_state\n",
        "\n",
        "  def update_fn(params, opt_state, rng, env_state):\n",
        "    \"\"\"Compute a gradient update from a single trajectory.\"\"\"\n",
        "    rng, loss_rng = random.split(rng)\n",
        "    grads, new_env_state = jax.grad(  # compute gradient on a single trajectory.\n",
        "        loss_fn, has_aux=True)(params, loss_rng, env_state)\n",
        "    grads = lax.pmean(grads, axis_name='j')  # reduce mean across cores.\n",
        "    grads = lax.pmean(grads, axis_name='i')  # reduce mean across batch.\n",
        "    updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
        "    new_params = optax.apply_updates(params, updates)  # update parameters.\n",
        "    return new_params, new_opt_state, rng, new_env_state\n",
        "\n",
        "  def learner_fn(params, opt_state, rngs, env_states):\n",
        "    \"\"\"Vectorise and repeat the update.\"\"\"\n",
        "    batched_update_fn = jax.vmap(update_fn, axis_name='j')  # vectorize across batch.\n",
        "    def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
        "      params, opt_state, rngs, env_states = val\n",
        "      return batched_update_fn(params, opt_state, rngs, env_states)\n",
        "    return lax.fori_loop(0, iterations, iterate_fn, (\n",
        "        params, opt_state, rngs, env_states))\n",
        "\n",
        "  return learner_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myLN2J47oNGq"
      },
      "source": [
        "def run_experiment(env, batch_size, rollout_len, step_size, iterations, seed):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "  cores_count = len(jax.devices())  # get available TPU cores.\n",
        "  network = get_network_fn(env.num_actions)  # define network.\n",
        "  optim = optax.adam(step_size)  # define optimiser.\n",
        "\n",
        "  rng, rng_e, rng_p = random.split(random.PRNGKey(seed), num=3)  # prng keys.\n",
        "  dummy_obs = env.render(env.initial_state(rng_e))[None,]  # dummy for net init.\n",
        "  params = network.init(rng_p, dummy_obs)  # initialise params.\n",
        "  opt_state = optim.init(params)  # initialise optimiser stats.\n",
        "\n",
        "  learn = get_learner_fn(  # get batched iterated update.\n",
        "      env, network.apply, optim.update, rollout_len=rollout_len,\n",
        "      agent_discount=1, lambda_=0.99, iterations=iterations)\n",
        "  learn = jax.pmap(learn, axis_name='i')  # replicate over multiple cores.\n",
        "\n",
        "  broadcast = lambda x: jnp.broadcast_to(x, (cores_count, batch_size) + x.shape)\n",
        "  params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
        "  opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
        "\n",
        "  rng, *env_rngs = jax.random.split(rng, cores_count * batch_size + 1)\n",
        "  env_states = jax.vmap(env.initial_state)(jnp.stack(env_rngs))  # init envs.\n",
        "  rng, *step_rngs = jax.random.split(rng, cores_count * batch_size + 1)\n",
        "\n",
        "  reshape = lambda x: x.reshape((cores_count, batch_size) + x.shape[1:])\n",
        "  step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
        "  env_states = reshape(env_states)  # add dimension to pmap over.\n",
        "\n",
        "  with TimeIt(tag='COMPILATION'):\n",
        "    learn(params, opt_state, step_rngs, env_states)  # compiles\n",
        "\n",
        "  num_frames = cores_count * iterations * rollout_len * batch_size\n",
        "  with TimeIt(tag='EXECUTION', frames=num_frames):\n",
        "    params, opt_state, step_rngs, env_states = learn(  # runs compiled fn\n",
        "        params, opt_state, step_rngs, env_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQO64MPNLVrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f964309-018e-483c-fe3b-e4aa2ad6ce10"
      },
      "source": [
        "print('Running on', len(jax.devices()), 'cores.', flush=True)  # !expected 8!\n",
        "run_experiment(Catch(), 128, 16, 1e-4, 100, 42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on 8 cores.\n",
            "COMPILATION: Elapsed time=4.08s\n",
            "EXECUTION: Elapsed time=0.37s, FPS=4.41e+06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbFQkOrRbTgK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}